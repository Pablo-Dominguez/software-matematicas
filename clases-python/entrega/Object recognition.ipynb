{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer vision en python\n",
    "\n",
    "El objetivo de este notebook es mostrar por un lado la capacidad de ciertas librerías de python en torno al _data augmentation_ y por otro lado aplicar esta técnica en un caso real de reconocimiento de objetos.\n",
    "\n",
    "Para ello, vamos a generar de forma aleatoria a partir de 5 imágenes básicas un conjunto de 250 imágenes, etiquetarlas y entrenar un modelo para luego realizar detección sobre dicho modelo. Dichas imágenes son las que se muestran a continuación.\n",
    "\n",
    "<img src=\"originales/taxi_01.jpg\" style=\"width: 45vw; min-width: 330px;\" />\n",
    "<img src=\"originales/taxi_02.jpg\" style=\"width: 45vw; min-width: 330px;\" />\n",
    "<img src=\"originales/taxi_03.jpg\" style=\"width: 45vw; min-width: 330px;\" />\n",
    "<img src=\"originales/taxi_04.jpg\" style=\"width: 45vw; min-width: 330px;\" />\n",
    "<img src=\"originales/taxi_05.jpg\" style=\"width: 45vw; min-width: 330px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primer paso: Data augmentation\n",
    "\n",
    "Esta técnica se usa comúnmente en técnicas de visión computacional cuando los datos de los que disponemos no son suficientes para nuestro estudio. A _grosso modo_, la técnica consiste en alterar una imagen de forma que para el entrenamiento de nuestro modelo, pueda contar como una imagen diferente y que por tanto aporta información extra al modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos las librerías\n",
    "\n",
    "import os\n",
    "import imageio\n",
    "import imgaug as ia\n",
    "import imgaug.augmenters as iaa\n",
    "import random\n",
    "from PIL import Image\n",
    "from numpy import *\n",
    "from sympy import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos las 5 imágenes que vamos a emplear\n",
    "\n",
    "originales = {}\n",
    "\n",
    "for img_name in os.listdir(\"./originales\"):\n",
    "    name = img_name.split('.')[0]\n",
    "    originales[name] = imageio.imread(\"./originales/\"+img_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_image(img):\n",
    "    \"\"\"\n",
    "    Esta función toma como argumento una imagen a la que de forma aleatoria se le van a aplicar con probabilidad 0.25 una de las siguientes transformaciones:\n",
    "    - Rotación.\n",
    "    - Rotación y reflexión.\n",
    "    - Rotación y ruido.\n",
    "    - Torsión.\n",
    "    \n",
    "    Todas ellas también con un grado aleatorio de alteración.\n",
    "    \"\"\"\n",
    "    x = random.randint(-50, 50)\n",
    "    y = random.randint(-50, 50)\n",
    "    z =  random.randint(1, 80)\n",
    "    if z <= 25: # rotamos la imagen\n",
    "        rotate=iaa.Affine(rotate=(x, y))\n",
    "        return rotate.augment_image(img)\n",
    "    elif z <= 50: # la rotamos y le hacemos una reflexión sobre el eje vertical\n",
    "        flip_hr=iaa.Fliplr(p=1.0)\n",
    "        rotate=iaa.Affine(rotate=(x, y))\n",
    "        return flip_hr.augment_image(rotate.augment_image(img))\n",
    "    elif z <= 75: # la rotamos y le agregamos ruido a la imagen\n",
    "        x = random.randint(-80, 80)\n",
    "        y = random.randint(-80, 80)\n",
    "        gaussian_noise=iaa.AdditiveGaussianNoise(-60,60)\n",
    "        rotate=iaa.Affine(rotate=(x, y))\n",
    "        return gaussian_noise.augment_image(rotate.augment_image(img))\n",
    "    else: # torcemos la imagen\n",
    "        x = random.randint(30, 60)\n",
    "        y = random.randint(30, 60)\n",
    "        shear = iaa.Affine(shear=(x,y))\n",
    "        return shear.augment_image(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generamos las 250 imágenes para el etiquetado y entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in originales.keys():\n",
    "    for j in range(50):\n",
    "        filename = \"random_image_{}_{}.jpg\".format(j,i)\n",
    "        imageio.imwrite(\"train/images/\"+filename, random_image(originales[i])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación podemos ver algunos ejemplos de las imágenes generadas:\n",
    "\n",
    "<img src=\"train/images/random_image_9_taxi_01.jpg\" style=\"width: 45vw; min-width: 330px;\" />\n",
    "<img src=\"train/images/random_image_8_taxi_03.jpg\" style=\"width: 45vw; min-width: 330px;\" />\n",
    "<img src=\"train/images/random_image_33_taxi_02.jpg\" style=\"width: 45vw; min-width: 330px;\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segundo paso: Etiquetado\n",
    "\n",
    "Necesitamos etiquetar de forma que el modelo pueda _aprender_ de las imágenes. Para ello, vamos a emplear la herramienta [LabelImg](https://pypi.org/project/labelImg/), que de forma muy sencilla nos permite etiquetar las imágenes tal y como se muestra en la imagen a continuación\n",
    "\n",
    "![alt_text](./resources/labelling.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tercer paso: Entrenamiento y evaluación del modelo\n",
    "\n",
    "Dado que para elaboración de la red neuronal necesitamos de una _GPU_, nos hemos apoyado en la herramienta [Google Colab](colab.research.google.com), que nos permite configurar un notebook para usarlo con este propósito. Las librerías que hemos empleado son las siguientes:\n",
    "\n",
    "* numpy==1.16.1\n",
    "* tensorflow-gpu==1.13.1\n",
    "* h5py==2.10.0\n",
    "* keras==2.2.4\n",
    "* imageai\n",
    "\n",
    "En primer lugar, para conectar nuestro notebook de google colab con nuestro google drive, que es desde donde capturará los datos el modelo, necesitamos ejecutar el siguiente bloque de código:\n",
    "\n",
    "```python\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "```\n",
    "\n",
    "Además, puesto que vamos a realizar __transfer learning__ sobre un modelo preentrenado, al que a su vez vamos a reentrenar nosotros con nuestros datos, necesitamos descargar dicho modelo. En concreto, el modelo que vamos a emplear es YOLOv3, que puede encontrarse [aquí](https://github.com/OlafenwaMoses/ImageAI/releases/download/essential-v4/pretrained-yolov3.h5).\n",
    "\n",
    "De forma que nuestro directorio de drive debe quedar con la siguiente estructura:\n",
    "\n",
    "```\n",
    "root/\n",
    "├── taxi/\n",
    "│   ├── train/\n",
    "│   │     ├── images/\n",
    "│   │     └── annotations/\n",
    "│   └── validation/\n",
    "│         ├── images/\n",
    "│         └── annotations/\n",
    "└── pretrained-yolov3.h5\n",
    "```\n",
    "\n",
    "En nuestro caso, hemos dividido 200 imágenes para el entrenamiendo, y 50 para la validación.\n",
    "\n",
    "Nota: Para movernos dentro de las carpetas de drive, podemos hacer uso del siguiente comando.\n",
    "\n",
    "```shell\n",
    "%cd drive/MyDrive/<folder>/<sub-folder>/<sub-sub-folder>/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento\n",
    "\n",
    "En cuanto al entrenamiendo, bastará con que ejecutemos el siguiente bloque de comandos. Es de destacar que sin un ordenador con soporte para _GPU_ y las librerías adecuadas instaladas, no podremos ejecutarlo. En nuestro caso realizamos el entrenamiendo con 70 etapas para no agotar los recursos de google colab.\n",
    "\n",
    "```python\n",
    "from imageai.Detection.Custom import DetectionModelTrainer\n",
    "\n",
    "trainer = DetectionModelTrainer()\n",
    "trainer.setModelTypeAsYOLOv3()\n",
    "trainer.setDataDirectory(data_directory=\"taxi\")\n",
    "trainer.setTrainConfig(object_names_array=[\"taxi\"], batch_size=4, num_experiments=70, train_from_pretrained_model=\"pretrained-yolov3.h5\")\n",
    "trainer.trainModel()\n",
    "```\n",
    "\n",
    "Una vez finalizado el entrenamiento, obtenemos numerosas carpetas que el modelo ha creado en nuestro directorio de trabajo. En concreto, la carpeta `models` es donde se almacenan las iteraciones del modelo, y cogeremos la última pues esta será la que tiene menor tasa de error. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación \n",
    "\n",
    "Para evaluar el modelo, simplemente deberemos ejecutar el siguiente bloque de código, sustituyendo los nombres de los archivos a cargar y el nombre del archivo a guardar en la línea de `detections`.\n",
    "\n",
    "```python\n",
    "from imageai.Detection.Custom import CustomObjectDetection\n",
    "\n",
    "detector = CustomObjectDetection()\n",
    "detector.setModelTypeAsYOLOv3()\n",
    "detector.setModelPath(\"taxi/models/detection_model-ex-057--loss-0002.068.h5\") \n",
    "detector.setJsonPath(\"taxi/json/detection_config.json\")\n",
    "detector.loadModel()\n",
    "\n",
    "detections = detector.detectObjectsFromImage(input_image=\"taxi/taxi_goal.jpg\", output_image_path=\"taxi-detected.jpg\")\n",
    "\n",
    "for detection in detections:\n",
    "    print(detection[\"name\"], \" : \", detection[\"percentage_probability\"], \" : \", detection[\"box_points\"])\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "En la siguiente tabla se muestran algunos resultados del modelo.\n",
    "\n",
    "| Original        | Resultado           |\n",
    "| :-------------: |:-------------:|\n",
    "| ![alt_text](./deteccion/taxi_goal2.jpg)      | ![alt_text](./outputs/taxi-detected2.jpg) |\n",
    "| ![alt_text](./deteccion/taxi_goal.jpg)      | ![alt_text](./outputs/taxi-detected.jpg) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "\n",
    "Únicamente partiendo de 5 imágenes iniciales, y generando a partir de ellas 200 imágenes de entrenamiento, hemos logrado entrenar una red neuronal capaz de detectar taxis. Si dispusiéramos de un mayor conjunto de entrenamiento, junto con una mayor capacidad computacional, aplicando las técnicas de _data augmentation_ que se presentan en este informe sin duda pueden conseguirse resultados realmente precisos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursos\n",
    "\n",
    "Para la elaboración de este informe, nos hemos basado en los siguientes artículos:\n",
    "\n",
    "* Para la creación del modelo: [Medium: Train Object Detection AI with 6 lines of code](https://medium.com/deepquestai/train-object-detection-ai-with-6-lines-of-code-6d087063f6ff)\n",
    "* Para el etiquetado: [Medium: Object Detection Training — Preparing your custom dataset](https://medium.com/deepquestai/object-detection-training-preparing-your-custom-dataset-6248679f0d1d)\n",
    "\n",
    "Todos los archivos necesarios, junto con el modelo generado, se pueden encontrar en el siguiente repositorio de Github.\n",
    "\n",
    "[Github Object Recognition](https://github.com/Pablo-Dominguez/software-matematicas/tree/master/clases-python-v2/entrega)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
